>>> Make database table:
    CREATE TABLE {table_name} (
      id INT NOT NULL AUTO_INCREMENT,
      dt DATETIME(6),
      img MEDIUMBLOB,
      PRIMARY KEY (id)
    );
>>> Make different folder for the node.js and next.js
>>> Go to node.js folder and install the following:
    > npm install express
    > npm install mysql2
    > npm install body-parser
>>> Go to next.js folder and install the following:
    > npx create-next-app@latest
>>> Make python file to the node.js folder and paste the code
        there (capture movement)
>>> Make index.js file to the node.js folder and paste the
        code for backend there
>>> Make images folder inside the node.js folder (folder for saving captured movements)
>>> Make image.js file to the next.js folder/pages and paste
        the code for front end there
>>> Run first the backend, then the front end and run this into
        the search engine: (localhost:{port}/image), lastly the
        python file

#############################################################################
=============================================================================
=============================================================================
#############################################################################

******** index.js ********

const express = require("express");
const mysql = require("mysql2");
const bodyParser = require("body-parser")
const app = express();
const port = 4000;
const db = "cpet17";
const db_table = "nextjs";


app.listen(port, () => {
    console.log(`ðŸš€ Server started at http://localhost:${port}`)
})

// create the connection to database
const connection = mysql.createConnection({
    host: "localhost",
    user: "root",
    password: "",
    database: `${db}`,
});

// throw error if connection failed
connection.connect(function (err) {
    if (err) throw err;
    console.log("Connected to Database!");
});

// parse application/x-www-form-urlencoded
app.use(bodyParser.urlencoded({ extended: false }))

// parse application/json
app.use(bodyParser.json())

app.post('/capture', (req, res)=> {
    // get the request json
    var { dateTime, img } = req.body;
  
    // save datetime, imgfile, into the db
    connection.query(`INSERT INTO ${db_table} (date_time, img) VALUES (?, ?);`,
    [dateTime, img],
    (err, result)=> {
        try {
            if (result.affectedRows > 0) {
            res.json({ data: "Success" });
        } else {
          res.json({ message: "Something went wrong." });
        }
        } catch {
            res.json({ message: err });
        }
    })
})

app.get('/show-images', (req, res)=> {
    // Select the last entry from the db
    connection.query(`SELECT * FROM ${db_table} ORDER BY id DESC LIMIT 1;`,
    (err, results)=> {
        try {
            if (results.length > 0) {
                // send a json response containg the image data (blob)
                res.json({'imgData': results[0]['img']});
        } else {
          res.json({ message: "Something went wrong." });
        }
        } catch {
            res.json({ message: err });
        }
    })
})

=====================================================================
=====================================================================

******** image.js ********

function ShowImage({ data }) {
    // Get the image data
    const image = data.imgData.data;

    // Convert into blob into string with charset=utf-8
    const base64Image = Buffer.from(image, 'base64').toString('utf-8');

    // Configure the image tag attribute (src)
    const imgSrc = "data:image/png;base64," + base64Image;
    
    // Render into HTML
    return (
        <div>
            <img src={imgSrc} />
        </div>
    )
}

export async function getServerSideProps() {
    // Fetch data from the server
    const response = await fetch('http://localhost:4000/show-images');

    // Get the json response
    const data = await response.json();
    return {
        props: { data },
    }
}

export default ShowImage

=====================================================================
=====================================================================

******** python file ********

import cv2, time, pandas, requests, base64
from datetime import datetime

# Assigning our static_back to None
static_back = None
  
# List when any moving object appear
motion_list = [ None, None ]
  
# Time of movement
time = []
  
# Initializing DataFrame, one column is start 
# time and other column is end time
df = pandas.DataFrame(columns = ["Start", "End"])
  
# Capturing video
video = cv2.VideoCapture(0)

# number of frames captured with movements
count = 0

def convertToBinaryData(filename):
    # Convert digital data to binary format
    with open(filename, 'rb') as file:
        imageBase64 = base64.b64encode(file.read())
    return imageBase64.decode('utf-8')
  
# Infinite while loop to treat stack of image as video
while True:
    # Reading frame(image) from video
    _, frame = video.read()
  
    # Initializing motion = 0(no motion)
    motion = 0
  
    # Converting color image to gray_scale image
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
  
    # Converting gray scale image to GaussianBlur 
    # so that change can be find easily
    gray = cv2.GaussianBlur(gray, (21, 21), 0)
  
    # In first iteration we assign the value 
    # of static_back to our first frame
    if static_back is None:
        static_back = gray
        continue
  
    # Difference between static background 
    # and current frame(which is GaussianBlur)
    diff_frame = cv2.absdiff(static_back, gray)
  
    # If change in between static background and
    # current frame is greater than 110 it will show white color(255)
    thresh_frame = cv2.threshold(diff_frame, 120, 255, cv2.THRESH_BINARY)[1]
    thresh_frame = cv2.dilate(thresh_frame, None, iterations=1)
  
    # Finding contour of moving object
    contours, _ = cv2.findContours(thresh_frame.copy(), 
                    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  
    for contour in contours:
        if cv2.contourArea(contour) < 10000:
            continue
        motion = 1
  
        (x, y, w, h) = cv2.boundingRect(contour)
        # making red rectangle around the moving object
        # putting text above the rectangle
        box = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
        cv2.putText(box, 'Movement Detected!', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,
                    0.5, (0, 0, 255), 1, cv2.LINE_AA)
  
    # Appending status of motion
    motion_list.append(motion)
    motion_list = motion_list[-2:]
    
    # get the current datetime
    time_now = datetime.now()

    # Appending Start time of motion
    if motion_list[-1] == 1 and motion_list[-2] == 0:
        time.append(time_now)
  
    # Appending End time of motion
    elif motion_list[-1] == 0 and motion_list[-2] == 1:
        time.append(time_now)

        # Save the captured frame
        file = f"images/frame{count}.jpg"
        cv2.imwrite(file, frame)

        # Get the absolute path of saved image (frame)
        # img = os.path.abspath(filepath)
        base64img = convertToBinaryData(file)

        # Increment the count value
        count += 1

        # Make a request
        data = {"dateTime": str(time_now), "img": str(base64img)}
        res = requests.post('http://localhost:4000/capture', json=data)

        # Display the json response
        print(res.json())

    # Displaying the black and white image in which if
    # intensity difference greater than 110 it will appear white
    cv2.imshow("Threshold Frame", thresh_frame)
  
    # Displaying color frame with contour of motion of object
    cv2.imshow("Color Frame", frame)
  
    key = cv2.waitKey(1)
    # if q entered whole process will stop
    if key == ord('q'):
        # if something is moving then it append the end time of movement
        if motion == 1:
            time.append(datetime.now())
        break

video.release()
cv2.destroyAllWindows()